---
title: "Simulations"
output: html_notebook
editor_options: 
  chunk_output_type: inline
---

```{r}
library(pROC)
library(ggplot2)
library(MASS)
library(e1071)
```

```{r}
library(caret)
set.seed(1000)
auc <- 0
```

```{r}
d <- 5 # dimensions
N <- 1000 # number of generated samples

```

```{r}
covariance.matrix <- matrix(1/2, nrow = d, ncol = d)

index <- c(1:d)

covariance.matrix[4,index[!index %in% 4]] = 1/sqrt(2)
covariance.matrix[index[!index %in% 4],4] = 1/sqrt(2)

covariance.matrix[5,index[!index %in% 5]] = 0
covariance.matrix[index[!index %in% 5],5] = 0

for(i in 1:d)
{
  covariance.matrix[i,i] <- 1
}
```

```{r}
covariance.matrix
```

```{r}
X <- mvrnorm(N,rep(0,d),covariance.matrix)
X <- cbind(rep(1,nrow(X)),X)
beta_hat <- c(-7,rep(4,3),-6*sqrt(2),4/3,rep(0,d-5))
```

```{r}
product.function <- X %*% beta_hat
df <- data.frame(cbind(X[,-1],product.function))
  
df$odds <- exp(product.function)/(1 + exp(product.function))
df$class <- ifelse(df$odds > 0.5,1,0)
names(df)[d+1] <- "logits"
names(df)[d+2] <- "pi_hat"
names(df)[d+3] <- "label"
  
df_1 <- df[,-c(d+1,d+2)]
```

```{r}
df_1
```

```{r}
t <- sample(1:N,0.35*N)
df_training <- df_1[t,]
df_test <- df_1[-t,]
```

```{r}
model <- svm(label~.,data = df_training,type="C-classification",probability = TRUE,kernel="polynomial")
predicted.classes <- predict(model,df_test[,-(d+1)],probability = TRUE)
```

```{r}
predicted.classes
```

```{r}
library(ROCR)
  
prob = attr(predicted.classes, "probabilities")[ ,2]
pred.roc = prediction(prob, labels = df_test$label)
  
roc.curve = performance(pred.roc, measure = "tpr", x.measure = "fpr")
auc = performance(pred.roc, measure="auc")@y.values
  
plot(roc.curve, lwd=2, col="deepskyblue")
title("ROC curve polynomial kernel", adj=0)
```

```{r}
set.seed(1000)
d <- 100 # dimensions
N <- 1000 # number of generated samples
covariance.matrix <- matrix(1/2, nrow = d, ncol = d)

index <- c(1:d)

covariance.matrix[4,index[!index %in% 4]] = 1/sqrt(2)
covariance.matrix[index[!index %in% 4],4] = 1/sqrt(2)

covariance.matrix[5,index[!index %in% 5]] = 0
covariance.matrix[index[!index %in% 5],5] = 0

for(i in 1:d)
{
  covariance.matrix[i,i] <- 1
}
X <- mvrnorm(N,rep(0,d),covariance.matrix)
X <- cbind(rep(1,nrow(X)),X)
beta_hat <- c(-7,rep(4,3),-6*sqrt(2),4/3,rep(0,d-5))
product.function <- X %*% beta_hat
df <- data.frame(cbind(X[,-1],product.function))
  
df$odds <- exp(product.function)/(1 + exp(product.function))
df$class <- ifelse(df$odds > 0.5,1,0)
names(df)[d+1] <- "logits"
names(df)[d+2] <- "pi_hat"
names(df)[d+3] <- "label"
  
df_1 <- df[,-c(d+1,d+2)]
df_1
```

```{r}
# getwd()
```

Exporting the generated data in csv file to C:/Users/Owner/Desktop

```{r}
write.csv(df_1,"C:/Users/Owner/Desktop/data.csv")
```

Frequency distribution of the generated data for the minority class (or 1's) and the majority class (or 0's)

```{r}
hist(df_1$label,xlab = "class",main = "Distribution of classes")
```

```{r}
average.auc <- 0
for (trial in 1:100) {
  
  t <- sample(1:N,0.35*N)
  df_training <- df_1[t,]
  df_test <- df_1[-t,]
  model <- svm(label~.,data=df_training,type="C-classification",probability = TRUE,kernel="polynomial")
  predicted.classes <- predict(model,df_test[,-(d+1)],probability = TRUE)
  
  prob = attr(predicted.classes, "probabilities")[ ,2]
  pred.roc = prediction(prob, labels = df_test$label)
  
  roc.curve = performance(pred.roc, measure = "tpr", x.measure = "fpr")
  auc = performance(pred.roc, measure="auc")@y.values
  average.auc <- average.auc + as.numeric(auc)
  
}

average.auc <- average.auc/100
```

```{r}
average.auc
```

```{r}
setwd("C:/Users/Owner/Desktop")
consolidated <- read.csv("test.csv",header = TRUE)
head(consolidated)
```

```{r}
simulation_results <- ggplot(consolidated,aes(x=temperature)) + geom_line(aes(y = AUC,color = p))
simulation_results + facet_grid(dimension~.)
```

Ordinal CDF

1.  Installation of the necessary packages

```{r}
ipak <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
  if (length(new.pkg))
    install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE)
}

packages <- c("mvtnorm","ggplot2","caret","ipred","devtools","sm","tidyr","dplyr","nnet","viridis","plotly","scatterplot3d", "patchwork")
ipak(packages)

library(MASS)
library(mvtnorm)
library(ggplot2)
library(caret)
library(ipred)
library(devtools)
library(sm)
library(tidyr)
library(dplyr)
# library(plotly)
library(viridis)
library(scatterplot3d)
library(patchwork)
library(e1071)
library(nnet)
set.seed(1000)
```

2.  data generation from several correlated univariate Gaussian populations

```{r}
d <- 5
num_of_classes <- 4
num_of_trials <- 100
alphas <- c(0.01,0.05,0.1,0.15,0.2)
N <- 1000
covariance.matrix <- matrix(0.2,ncol = d,nrow = d)
for (index in 1:d) {
  covariance.matrix[index,index] <- 1
}
beta_hat <- c(0,rep(1,3),-sqrt(2),1,rep(0,d-5))
X <- mvrnorm(N,rep(0,d),covariance.matrix)
X <- cbind(rep(1,nrow(X)),X)
product.function <- X %*% beta_hat
df <- data.frame(cbind(X[,-1],product.function))

df$odds <- exp(product.function)/(1+exp(product.function))
for(i in 1:length(df$odds))
{
  for(class in 0:num_of_classes)
  {
    if(df$odds[i] >= class/num_of_classes && df$odds[i] < (class+1)/num_of_classes)
      df$labels[i] <- class + 1
  }
}

df <- df[,-c(d+1,d+2)]
head(df)
```

3.  training the base classifier and includes the calibration and validation scores that are 35% and 65% of the test observations respectively

```{r}
training.index <- sample(1:N,100)
df_training <- df[training.index,]
df_test <- df[-training.index,]
multinomial_model <- multinom(labels~.,data = df_training)
    
cal_pct <- 0.35
    
calibration.indexes <- createDataPartition(y=df_test$labels,p=cal_pct,list=FALSE)
df_calibration <- df[calibration.indexes,]
df_validation <- df[-calibration.indexes,]
    
cal_scores <- predict(multinomial_model,newdata = df_calibration[,-(d+1)],"probs")
cal_labels <- df_calibration$labels

val_scores <- predict(multinomial_model,newdata = df_validation[,-(d+1)],"probs")
val_labels <- df_validation$labels

# head(cal_scores)
```

CDF ordinal score function

```{r}
cusum_cal <- list()
cusum_cal <- vector("list",length = nrow(cal_scores))
argmaxes <- NULL
conformity_scores <- NULL
for (i in 1:nrow(cal_scores)) {
  
  cusum_cal[[i]] <- cumsum(cal_scores[i,])
  argmaxes[i] <- which.max(cal_scores[i,])
  t <- cusum_cal[[i]]
  conformity_scores[i] <- t[argmaxes[i]] - t[cal_labels[i]]
  
}
cusum_cal
```

```{r}
conformity_scores
```

```{r}
a <- 0.01
q <- floor((cal_pct*(N-100) + 1)*(1 - a))/(cal_pct*(N-100) + 1)
ordinal_cdf_qhat <- quantile(conformity_scores, probs = c(0.25,q))[2]
ordinal_cdf_qhat
```

```{r}
cusum_val <- list()
cusum_val <- vector("list",length = nrow(val_scores))
argmaxes <- NULL
prediction_interval <- matrix(0,ncol = 2,nrow = nrow(val_scores))
for (j in 1:nrow(val_scores)) 
{
  cusum_val[[j]] <- cumsum(val_scores[j,])
  argmaxes[j] <- which.max(val_scores[j,])
  t <- cusum_val[[j]]
  prediction_interval[j,1] <- min(which(t >= t[argmaxes[j]]-ordinal_cdf_qhat)) 
  prediction_interval[j,2] <- max(which(t <= t[argmaxes[j]]+ordinal_cdf_qhat))
}
prediction_interval
```

```{r}
head(prediction_interval)
```

Ordinal Adaptive Prediction Sets

```{r}
d <- 5
num_of_classes <- 4
num_of_trials <- 100
alphas <- c(0.01,0.05,0.1,0.15,0.2)
N <- 1000
covariance.matrix <- matrix(0.2,ncol = d,nrow = d)
for (index in 1:d) {
  covariance.matrix[index,index] <- 1
}
beta_hat <- c(0,rep(1,3),-sqrt(2),1,rep(0,d-5))
X <- mvrnorm(N,rep(0,d),covariance.matrix)
X <- cbind(rep(1,nrow(X)),X)
product.function <- X %*% beta_hat
df <- data.frame(cbind(X[,-1],product.function))

df$odds <- exp(product.function)/(1+exp(product.function))
for(i in 1:length(df$odds))
{
  for(class in 0:num_of_classes)
  {
    if(df$odds[i] >= class/num_of_classes && df$odds[i] < (class+1)/num_of_classes)
      df$labels[i] <- class + 1
  }
}

df <- df[,-c(d+1,d+2)]
training.index <- sample(1:N,100)
df_training <- df[training.index,]
df_test <- df[-training.index,]
multinomial_model <- multinom(labels~.,data = df_training)
    
cal_pct <- 0.35
    
calibration.indexes <- createDataPartition(y=df_test$labels,p=cal_pct,list=FALSE)
df_calibration <- df[calibration.indexes,]
df_validation <- df[-calibration.indexes,]
    
cal_scores <- predict(multinomial_model,newdata = df_calibration[,-(d+1)],"probs")
cal_labels <- df_calibration$labels

val_scores <- predict(multinomial_model,newdata = df_validation[,-(d+1)],"probs")
val_labels <- df_validation$labels
head(cal_scores)
```

OAPS implementation

```{r}
lambdas <- seq(0.0001,1-0.0001,0.0001)
lambda_hat <- NULL
for (row in 1:nrow(cal_scores)) {
  
  tmp <- cal_scores[row,]
  lower_edge <- which.max(tmp)
  upper_edge <- which.max(tmp)
  
  for(lambda in 1:length(lambdas)){
    q <- 0
    while(q <= lambda)
    {
      lower_edge <- lower_edge-1
      upper_edge <- upper_edge+1
      
      
    }
  }
  
  
  
}
```

```{r}
mydata<-read.csv("C:/Users/Owner/Desktop/dataset/earthquakes_NZ.csv",header = TRUE)
mydata <- mydata[,-1]
# pairs(mydata, pch = 10)

```

```{r}
library(PerformanceAnalytics)
chart.Correlation(mydata, histogram=TRUE, pch=19)
```

```{r}
histogram(mydata$magnitude,xlab = "magnitude of the earthquake")
```

```{r}
for(i in 1:nrow(mydata))
{
  if(mydata$magnitude[i] < 1.75)
    mydata$target[i] <- 4
  else if(mydata$magnitude[i] >= 1.75 & mydata$magnitude[i] < 2)
    mydata$target[i] <- 3
  else if(mydata$magnitude[i] >= 2 & mydata$magnitude[i] < 2.5)
    mydata$target[i] <- 2
  else
    mydata$target[i] <- 1
}
# hist(mydata$magnitude,main = "Distribution of magnitude")
# hist(mydata$target, main = "Distribution for the new coding",xlab = "magnitude of earthquake")
```

```{r}
N <- nrow(mydata)
num_of_trials <- 10
num_of_classes <- 4
alphas <- seq(0.01,0.15,0.01)


marginal_coverage_cdf <- matrix(0, nrow = length(alphas), ncol = num_of_trials)
marginal_coverage_lac <- matrix(0, nrow = length(alphas), ncol = num_of_trials)
marginal_coverage_opi <- matrix(0, nrow = length(alphas), ncol = num_of_trials)
marginal_coverage_ops <- matrix(0, nrow = length(alphas), ncol = num_of_trials)

set_size_cdf <- matrix(0, nrow = length(alphas), ncol = num_of_trials)
set_size_lac <- matrix(0, nrow = length(alphas), ncol = num_of_trials)
set_size_opi <- matrix(0, nrow = length(alphas), ncol = num_of_trials)
set_size_ops <- matrix(0, nrow = length(alphas), ncol = num_of_trials)
```

```{r}
N
mydata <- mydata[,-4]
View(mydata)

```

```{r}
View(df_calibration)
```

```{r}
    training.index <- sample(1:N,2000)
    df_training <- mydata[training.index,]
    df_test <- mydata[-training.index,]
    
    # logistic regression
    
    df_training$target <- as.factor(df_training$target)
    mod <- polr(target ~.,data = df_training,Hess = TRUE,method = "logistic")
    # p <- predict(mod, df_test[,-4])
    
    cal_pct <- 0.35
    
    calibration.indexes <- createDataPartition(y=df_test$target,p=cal_pct,list=FALSE)
    df_calibration <- mydata[calibration.indexes,]
    df_validation <- mydata[-calibration.indexes,]
    
    # Calibration data
    
    cal_probs <- predict(mod,newdata = df_calibration[,-4],"probs")
    cal_labels <- df_calibration$target
    
    cal_scores <- NULL
    
    for(i in 1:nrow(cal_probs))
      cal_scores[i] <- cal_probs[i,cal_labels[i]]
    
    # Validation data
    
    val_probs <- predict(mod,newdata = df_validation[,-4],"probs")
    val_labels <- df_validation$target
    
    p.values <- matrix(0,nrow = nrow(val_probs),ncol = num_of_classes)
    
    for(i in 1:nrow(val_probs))
    {
      for(j in 1:num_of_classes)
      {
        p.values[i,j] <- (sum(val_probs[i,j] >= cal_scores)+1)/(length(cal_scores) + 1)
      }
    }
```

```{r}
summary(mod)
```

```{r}
estimated_qhat <- function(conformity_scores,a)
{
  q <- floor((cal_pct*(N-2000) + 1)*(1 - a))/(cal_pct*(N-2000) + 1)
  qhat <- quantile(conformity_scores, probs = c(0.25,q))[2]
  return(qhat)
}
for(alpha in 1:length(alphas))
{
  for(trial in 1:num_of_trials)
  {
    training.index <- sample(1:N,2000)
    df_training <- mydata[training.index,]
    df_test <- mydata[-training.index,]
    
    # logistic regression
    
    multinomial_model <- multinom(target~.,data = df_training)
    
    cal_pct <- 0.35
    
    calibration.indexes <- createDataPartition(y=df_test$target,p=cal_pct,list=FALSE)
    df_calibration <- mydata[calibration.indexes,]
    df_validation <- mydata[-calibration.indexes,]
    
    # Calibration data
    
    cal_probs <- predict(multinomial_model,newdata = df_calibration[,-4],"probs")
    cal_labels <- df_calibration$target
    
    cal_scores <- NULL
    
    for(i in 1:nrow(cal_probs))
      cal_scores[i] <- cal_probs[i,cal_labels[i]]
    
    # Validation data
    
    val_probs <- predict(multinomial_model,newdata = df_validation[,-4],"probs")
    val_labels <- df_validation$target
    
    p.values <- matrix(0,nrow = nrow(val_probs),ncol = num_of_classes)
    
    for(i in 1:nrow(val_probs))
    {
      for(j in 1:num_of_classes)
      {
        p.values[i,j] <- (sum(val_probs[i,j] >= cal_scores)+1)/(length(cal_scores) + 1)
      }
    }
    
    ordinal_cdf_conformity_scores <- ordinal_CDF_score_function(cal_probs,cal_labels)
    lac_conformity_scores <- lac_score_function(cal_probs,cal_labels)
    
    Q_hat_cdf <- estimated_qhat(ordinal_cdf_conformity_scores,alphas[alpha])
    Q_hat_lac <- estimated_qhat(lac_conformity_scores, alphas[alpha])
    
    # ordinal cdf 
    
    cdf_prediction_interval <- ordinal_CDF_prediction_sets(val_probs,val_labels,Q_hat_cdf)
    cdf_coverage <- 0
    
    for(m in 1:nrow(cdf_prediction_interval))
    {
      if(cdf_prediction_interval[m,1] <= val_labels[m] && val_labels[m] <= cdf_prediction_interval[m,2] )
        cdf_coverage <- cdf_coverage + 1
    }
    marginal_coverage_cdf[alpha,trial] <- cdf_coverage/length(val_labels)
    set_size_cdf[alpha,trial] <- mean(cdf_prediction_interval[,2] - cdf_prediction_interval[,1] + 1)
    
    # naive lac
    
    lac_prediction_set <- naive_lac_prediction_sets(val_probs,val_df,Q_hat_lac)
    lac_coverage <- 0
    
    for(m in 1:nrow(lac_prediction_set))
    {
      if(val_labels[m] %in% lac_prediction_set[m,])
        lac_coverage <- lac_coverage + 1
    }
    
    marginal_coverage_lac[alpha,trial] <- lac_coverage/length(val_labels)
    set_size_lac[alpha,trial] <- evaluate_set_size_for_lac(lac_prediction_set)
    
    # opi
    
    ordinal_prediction_intervals <- opi_prediction_intervals(p.values,alphas[alpha])
    opi_coverage <- 0
    
    for(m in 1:nrow(ordinal_prediction_intervals))
    {
      if(ordinal_prediction_intervals[m,1] <= val_labels[m] && val_labels[m] <= ordinal_prediction_intervals[m,2] )
        opi_coverage <- opi_coverage + 1
    }
    marginal_coverage_opi[alpha,trial] <- opi_coverage/length(val_labels)  
    set_size_opi[alpha,trial] <- mean(ordinal_prediction_intervals[,2] - ordinal_prediction_intervals[,1] + 1)
    
    # ops
    
    ordinal_prediction_sets <- opi_prediction_sets(p.values,alphas[alpha])
    ops_coverage <- 0
    
    for(m in 1:length(ordinal_prediction_sets))
    {
      if(val_labels[m] %in% as.vector(ordinal_prediction_sets[[m]]))
        ops_coverage <- ops_coverage + 1
    }
    marginal_coverage_ops[alpha,trial] <- ops_coverage/length(val_labels)
    set_size_ops[alpha,trial] <- evaluate_set_size_ops(ordinal_prediction_sets)
  }
}


cal_df <- cbind(cal_probs,cal_labels)
val_df <- cbind(val_probs,val_labels)
mydat = data.frame(rbind(cal_df,val_df))
write.csv(data.frame(cbind(cal_probs,cal_labels)),"/Users/Owner/Desktop/mydata.csv")

average_cvg_cdf <- NULL
average_cvg_lac <- NULL
average_cvg_opi <- NULL
average_cvg_ops <- NULL

avg_set_size_cdf <- NULL
avg_set_size_lac <- NULL
avg_set_size_opi <- NULL
avg_set_size_ops <- NULL

for(alpha in 1:length(alphas))
{
  average_cvg_cdf[alpha] <- mean(marginal_coverage_cdf[alpha,])
  average_cvg_lac[alpha] <- mean(marginal_coverage_lac[alpha,])
  average_cvg_opi[alpha] <- mean(marginal_coverage_opi[alpha,])
  average_cvg_ops[alpha] <- mean(marginal_coverage_ops[alpha,])
  
  avg_set_size_cdf[alpha] <- mean(set_size_cdf[alpha,][is.finite(set_size_cdf[alpha,])])
  avg_set_size_lac[alpha] <- mean(set_size_lac[alpha,])
  avg_set_size_opi[alpha] <- mean(set_size_opi[alpha,][is.finite(set_size_opi[alpha,])])
  avg_set_size_ops[alpha] <- mean(set_size_ops[alpha,])
}
```

```{r}
cal_df <- cbind(cal_probs,cal_labels)
val_df <- cbind(val_probs,val_labels)
mydat = data.frame(rbind(cal_df,val_df))
write.csv(data.frame(cbind(cal_probs,cal_labels)),"/Users/Owner/Desktop/mydata.csv")

average_cvg_cdf <- NULL
average_cvg_lac <- NULL
average_cvg_opi <- NULL
average_cvg_ops <- NULL

avg_set_size_cdf <- NULL
avg_set_size_lac <- NULL
avg_set_size_opi <- NULL
avg_set_size_ops <- NULL

for(alpha in 1:length(alphas))
{
  average_cvg_cdf[alpha] <- mean(marginal_coverage_cdf[alpha,])
  average_cvg_lac[alpha] <- mean(marginal_coverage_lac[alpha,])
  average_cvg_opi[alpha] <- mean(marginal_coverage_opi[alpha,])
  average_cvg_ops[alpha] <- mean(marginal_coverage_ops[alpha,])
  
  avg_set_size_cdf[alpha] <- mean(set_size_cdf[alpha,][is.finite(set_size_cdf[alpha,])])
  avg_set_size_lac[alpha] <- mean(set_size_lac[alpha,])
  avg_set_size_opi[alpha] <- mean(set_size_opi[alpha,][is.finite(set_size_opi[alpha,])])
  avg_set_size_ops[alpha] <- mean(set_size_ops[alpha,])
}
```

```{r}
summary(multinomial_model)
```

```{r}

average_cvg_aps <- c(0.9907376855998116,
 0.982041008720245,
 0.9724487390996936,
 0.9615130803676643,
 0.9500589205750648,
 0.9392882394532169,
 0.9306151308036765,
 0.9226255008248879,
 0.9165448974781993,
 0.8969125618666037,
 0.8872495875559746,
 0.8824416686306857,
 0.8665802498232382,
 0.8597218948856942,
 0.846830073061513)

results_average_cvg_multinom <- data.frame(cbind(alphas,average_cvg_aps,average_cvg_cdf,average_cvg_lac,average_cvg_opi,average_cvg_ops))

plt_1 <- ggplot(data = results_average_cvg_multinom, aes(x = alphas))+
  geom_line(aes(y = average_cvg_cdf,color = "Ordinal CDF")) +
  geom_line(aes(y = average_cvg_lac,color = "Naive LAC")) +
  geom_line(aes(y = average_cvg_aps, color = "Ordinal APS")) +
  geom_line(aes(y = average_cvg_opi,color = "Ordinal Prediction Interval")) +
  geom_line(aes(y = average_cvg_ops,color = "Ordinal Prediction Sets")) +
  labs(x = "alphas", y = "Marginal coverage", color = "Legend")
plt_1
```

```{r}
avg_set_size_aps <- c(3.8294131510723544,
 3.769714824416687,
 3.7196323356115952,
 3.6267970775394773,
 3.508319585199152,
 3.4213999528635397,
 3.359415507895357,
 3.2751119490926235,
 3.1966533113363185,
 3.0753476313928823,
 3.0110534998821588,
 2.9745698798020266,
 2.9068583549375444,
 2.877987273155786,
 2.8333254772566585)

results_average_set_size_multinom <- data.frame(cbind(alphas, avg_set_size_aps,avg_set_size_cdf, avg_set_size_lac, avg_set_size_opi, avg_set_size_ops))

ggplt_2 <- ggplot(data = results_average_set_size_multinom,aes(x = alphas)) +
  geom_line(aes(y = avg_set_size_cdf,color = "Ordinal CDF")) +
  geom_line(aes(y = avg_set_size_lac,color = "Naive LAC")) +
  geom_line(aes(y = avg_set_size_aps, color = "Ordinal APS")) +
  geom_line(aes(y = avg_set_size_opi,color = "Ordinal Prediction Interval")) +
  geom_line(aes(y = avg_set_size_ops,color = "Ordinal Prediction Sets")) +
  labs(x = "alphas", y = "Set size", color = "Legend") + ylim(0,4)

ggplt_2
```

```{r}

```

```{r}
cond_coverage_lac <- matrix(0,nrow = num_of_classes,ncol = length(alphas))
cond_coverage_cdf <- matrix(0,nrow = num_of_classes,ncol = length(alphas))
cond_coverage_opi <- matrix(0,nrow = num_of_classes,ncol = length(alphas))
cond_coverage_ops <- matrix(0,nrow = num_of_classes,ncol = length(alphas))

for(alpha in 1:length(alphas))
{
 training.index <- sample(1:N,2000)
    df_training <- mydata[training.index,]
    df_test <- mydata[-training.index,]
    
    # logistic regression
    
    multinomial_model <- multinom(target~.,data = df_training)
    
    cal_pct <- 0.35
    
    calibration.indexes <- createDataPartition(y=df_test$target,p=cal_pct,list=FALSE)
    df_calibration <- mydata[calibration.indexes,]
    df_validation <- mydata[-calibration.indexes,]
  
  # Calibration data
  
  cal_probs <- predict(multinomial_model,newdata = df_calibration[,-4],"probs")
  cal_labels <- df_calibration$target
  
  cal_scores <- NULL
  
  for(i in 1:nrow(cal_probs))
    cal_scores[i] <- cal_probs[i,cal_labels[i]]
  
  # Validation data
  
  val_probs <- predict(multinomial_model,newdata = df_validation[,-4],"probs")
  val_labels <- df_validation$target
  
  lac_conformity_scores <- lac_score_function(cal_probs,cal_labels)
  Q_hat_lac <- estimated_qhat(lac_conformity_scores, alphas[alpha])
  
  lac_prediction_set <- naive_lac_prediction_sets(val_probs,val_df,Q_hat_lac)
  
  for(class in 1:num_of_classes)
  {
    lac_conditional_cvg <- 0
    for(m in 1:nrow(lac_prediction_set))
    {
      if(val_labels[m] == class)
      {
        if(val_labels[m] %in% lac_prediction_set[m,])
          lac_conditional_cvg <- lac_conditional_cvg + 1
      }
    }
    cond_coverage_lac[class,alpha] <- lac_conditional_cvg/length(which(val_labels == class))
}
  
  ordinal_cdf_conformity_scores <- ordinal_CDF_score_function(cal_probs,cal_labels)
  Q_hat_cdf <- estimated_qhat(ordinal_cdf_conformity_scores,alphas[alpha])
  
  cdf_prediction_interval <- ordinal_CDF_prediction_sets(val_probs,val_labels,Q_hat_cdf)
  
  for(class in 1:num_of_classes)
  {
    cdf_conditional_cvg <- 0
    for(m in 1:nrow(cdf_prediction_interval))
    {
      if(val_labels[m] == class)
      {
        if(val_labels[m] %in% cdf_prediction_interval[m,])
          cdf_conditional_cvg <- cdf_conditional_cvg + 1
      }
    }
    cond_coverage_cdf[class,alpha] <- cdf_conditional_cvg/length(which(val_labels == class))
  }
  
  p.values <- matrix(0,nrow = nrow(val_probs),ncol = num_of_classes)
  
  for(i in 1:nrow(val_probs))
  {
    for(j in 1:num_of_classes)
    {
      p.values[i,j] <- (sum(val_probs[i,j] >= cal_probs[which(cal_labels == j),j])+1)/(length(cal_probs[which(cal_labels == j),j]) + 1)
    }
  }
  
  ordinal_prediction_intervals <- opi_prediction_intervals(p.values,alphas[alpha])
  ordinal_prediction_sets <- opi_prediction_sets(p.values,alphas[alpha])
  
  for(class in 1:num_of_classes)
  {
    opi_cond_cvg <- 0
    ops_cond_cvg <- 0
    
    for(m in 1:nrow(ordinal_prediction_intervals))
    {
      if(val_labels[m] == class)
      {
        if(ordinal_prediction_intervals[m,1] <= val_labels[m] && val_labels[m] <= ordinal_prediction_intervals[m,2] )
          opi_cond_cvg <- opi_cond_cvg + 1
      }
    }
    for(m in 1:length(ordinal_prediction_sets))
    {
      if(val_labels[m] == class)
      {
        if(val_labels[m] %in% as.vector(ordinal_prediction_sets[[m]]))
          ops_cond_cvg <- ops_cond_cvg + 1
      }
    }
    
    cond_coverage_opi[class,alpha] <- opi_cond_cvg/length(which(val_labels == class))
    cond_coverage_ops[class,alpha] <- ops_cond_cvg/length(which(val_labels == class))
  }
}

```

```{r}
aps_neg_cvg <- c(0.9678021473334304,
 0.9343066871200405,
 0.8955160251801635,
 0.8553626783826103,
 0.8085570451333155,
 0.765287437381949,
 0.7331191452605078,
 0.6982086629304182,
 0.6724150674812222,
 0.5971585136031445,
 0.5709946371580326,
 0.5599443649619249,
 0.5547593589208178,
 0.5547027449412637,
 0.550772381791306)
aps_mil_cvg <- c(1.0,
 1.0,
 1.0,
 1.0,
 0.9994354176601437,
 0.9977867842197756,
 0.9970920569856425,
 0.993337611841946,
 0.9905360983557738,
 0.9877646501116819,
 0.9768366321604258,
 0.9692322129342072,
 0.9333337458942846,
 0.9132146785071867,
 0.8907662428158769)
aps_mod_cvg <- c(0.9996034926968042,
 0.9995188755433959,
 0.9996832376422622,
 0.9994433191219276,
 0.9995214392473446,
 0.9995200936418775,
 0.9996031632286406,
 0.9995171319537363,
 0.9995203709545224,
 0.9986379229842679,
 0.9981447576412423,
 0.9975184994386895,
 0.9912660233047138,
 0.9827018174709385,
 0.964028808468929)
aps_sev_cvg <- c(0.9923226851972456,
 0.9869685971302864,
 0.9818440762556083,
 0.9735288187350042,
 0.9692137784300676,
 0.9644255226699805,
 0.9580137241773979,
 0.9584050777343978,
 0.9563253235300057,
 0.9465608688643137,
 0.9409484219884148,
 0.9366858019555057,
 0.9176664413896685,
 0.9134921824655567,
 0.9053395942405433)

cond_coverage_aps <- rbind(aps_sev_cvg,aps_mod_cvg,aps_mil_cvg,aps_neg_cvg)

lac_conditional_coverage <- NULL
cdf_conditional_coverage <- NULL
opi_conditional_coverage <- NULL
ops_conditional_coverage <- NULL
aps_conditional_coverage <- NULL

for(alpha in 1:length(alphas))
{
  lac_conditional_coverage[alpha] <- max((1-alphas[alpha]) - cond_coverage_lac[,alpha],0)
  cdf_conditional_coverage[alpha] <- max((1-alphas[alpha]) - cond_coverage_cdf[,alpha],0)
  opi_conditional_coverage[alpha] <- max((1-alphas[alpha]) - cond_coverage_opi[,alpha],0)
  ops_conditional_coverage[alpha] <- max((1-alphas[alpha]) - cond_coverage_ops[,alpha],0)
  aps_conditional_coverage[alpha] <- max((1-alphas[alpha]) - cond_coverage_aps[,alpha],0)
}
  
```

```{r}
conditional_coverage_plot <- plot_ly(x=~alphas)
conditional_coverage_plot <- conditional_coverage_plot %>% add_lines(y=~cond_coverage_cdf,name="<b>Ordinal CDF")
conditional_coverage_plot <- conditional_coverage_plot %>% add_lines(y=~cond_coverage_aps,name="<b>Ordinal APS")
conditional_coverage_plot <- conditional_coverage_plot %>% add_lines(y=~cond_coverage_lac,name="<b>Naive LAC")
conditional_coverage_plot <- conditional_coverage_plot %>% add_lines(y=~cond_coverage_opi,name="<b>Ordinal Prediction Interval")
conditional_coverage_plot <- conditional_coverage_plot %>% add_lines(y=~cond_coverage_ops,name="<b>Ordinal Prediction Set")
conditional_coverage_plot <- conditional_coverage_plot %>% layout(xaxis = list(title = "miscoverage"),yaxis = list(title = "conditional coverage",range = c(0,1)),title = "conditional coverage")
conditional_coverage_plot
```

```{r}
results_conditional_cvg_multinom <- data.frame(cbind(alphas,aps_conditional_coverage ,cdf_conditional_coverage, lac_conditional_coverage, opi_conditional_coverage, ops_conditional_coverage))

ggplt_3 <- ggplot(data = results_conditional_cvg_multinom,aes(x = alphas)) +
  geom_line(aes(y = cdf_conditional_coverage,color = "Ordinal CDF")) +
  geom_line(aes(y = lac_conditional_coverage,color = "Naive LAC")) +
  geom_line(aes(y = aps_conditional_coverage, color = "Ordinal APS")) +
  geom_line(aes(y = opi_conditional_coverage,color = "Ordinal Prediction Interval")) +geom_line(aes(y = ops_conditional_coverage,color = "Ordinal Prediction Sets")) +
  labs(x = "alphas", y = "CCV", color = "Legend")

ggplt_3
```

```{r}
results_conditional_cvg_multinom

```

```{r}
ggarrange(plt_1,ggplt_2,ggplt_3,ncol = 3, nrow = 1, common.legend = TRUE, legend = "bottom")
```

Ovarian Cancer data

```{r}
cancer_data<-read.csv("C:/Users/Owner/Desktop/dataset/NIHMS313090-supplement-12.csv",header = TRUE)
```

```{r}
head(cancer_data)
```

```{r}

```
